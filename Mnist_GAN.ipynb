{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mnist_GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeChungHyun/TensorFlow/blob/master/Mnist_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZGJhZlmCPXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbEwTBKnCTsN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p05YcmSRCVmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lbgcpbfCq8D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "233fd828-ec64-44db-ceb5-da2779390cc1"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
        "\n",
        "#실제 이미지는 28*28=784개의 특징을 가진다.\n",
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "\n",
        "#가짜 이미지를 위해 필요한 노이즈의 크기는 128입니다.\n",
        "Z = tf.placeholder(tf.float32, [None, 128])\n",
        "\n",
        "#생성자 128(노이즈) -> 256(은닉층) ->784(입력층)\n",
        "G_W1 = tf.Variable(tf.random_normal([128, 256], stddev=0.01))\n",
        "G_b1 = tf.Variable(tf.zeros([256]))\n",
        "G_W2 = tf.Variable(tf.random_normal([256, 784], stddev=0.01))\n",
        "G_b2 = tf.Variable(tf.zeros([784]))\n",
        "\n",
        "#구분자 784(입력층) -> 256(은닉층) -> 0~1(일치도)   \n",
        "D_W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
        "D_b1 = tf.Variable(tf.zeros([256]))\n",
        "D_W2 = tf.Variable(tf.random_normal([256, 1], stddev=0.01))\n",
        "D_b2 = tf.Variable(tf.random_normal([1]))\n",
        " \n",
        "#생성자 객체를 생성하는 함수\n",
        "def generator(noise):\n",
        "    hidden = tf.nn.relu(tf.matmul(noise, G_W1) + G_b1)\n",
        "    output = tf.nn.sigmoid(tf.matmul(hidden, G_W2) + G_b2)\n",
        "    return output\n",
        " \n",
        "#구분자 객체를 생성하는 함수\n",
        "def discriminator(inputs):\n",
        "    hidden = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
        "    output = tf.nn.sigmoid(tf.matmul(hidden, D_W2) + D_b2)\n",
        "    return output\n",
        " \n",
        "#무작위 노이즈를 생성한다.\n",
        "def get_noise(batch_size, noise):\n",
        "    return np.random.normal(size=(batch_size, noise))\n",
        "\n",
        "#가짜 이미지 생성자는 128 크기의 노이즈에서 불러온다\n",
        "G = generator(Z)\n",
        "#가짜 이미지 구분자는 128크기의 노이즈가 생성한 784크기의 이미지에서 불러온다.\n",
        "D_gene = discriminator(G)\n",
        "#실제 이미지 구분자는 784크기의 이미지에서 불러온다.\n",
        "D_real = discriminator(X)\n",
        "\n",
        "#구분자의 손실함수는 진짜 이미지가 1에 가깝고, 가짜 이미지는 0에 가깝다.  \n",
        "loss_D = tf.reduce_mean(tf.log(D_real) + tf.log(1 - D_gene))\n",
        "#생성자의 손실함수는 진짜 이미지가 0에 가깝고, 가짜 이미지는 1에 가깝다.\n",
        "loss_G = tf.reduce_mean(tf.log(D_gene))\n",
        "\n",
        "#모델 학습 준비하기\n",
        "#구분자는 구분자 가중치 및 바이어스 사용\n",
        "D_var_list = [D_W1, D_b1, D_W2, D_b2]\n",
        "#생성자는 생성자 가중치 및 바이어스 사용\n",
        "G_var_list = [G_W1, G_b1, G_W2, G_b2]\n",
        "\n",
        "#구분자 최적화 진행\n",
        "train_D = tf.train.AdamOptimizer(0.0002).minimize(-loss_D, var_list=D_var_list)\n",
        "#생성자 최적화 진행\n",
        "train_G = tf.train.AdamOptimizer(0.0002).minimize(-loss_G, var_list=G_var_list)\n",
        "\n",
        "#세션을 생성해 그래프 동작\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    #구분자와 생성자의 비용 변수를 생성한다.\n",
        "    loss_val_D, loss_val_G = 0, 0\n",
        "\n",
        "    #배치 크기를 100으로 설정한다.\n",
        "    batch_size = 100\n",
        "    total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "\n",
        "    #총 100번 학습 진행\n",
        "    for epoch in range(500):\n",
        "        #전체 배치 크기만큼 반복한다.\n",
        "            for i in range(total_batch):\n",
        "                batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "                noise = get_noise(batch_size, 128)\n",
        "        #구분자는 실제 이미지 및 노이즈를 이용해 학습을 진행시킨다.\n",
        "                _, loss_val_D = sess.run([train_D, loss_D],\n",
        "                    feed_dict={X: batch_x, Z: noise})\n",
        "        #생성자는 노이즈만을 이용해 학습 진행        \n",
        "                _, loss_val_G = sess.run([train_G, loss_G],\n",
        "                    feed_dict={Z: noise})\n",
        "        #1번 돌때마다 학습 상황 출력\n",
        "            print('학습:', '%04d' % epoch,\n",
        "                '구분자 오차: {:.4}'.format(loss_val_D),\n",
        "                '생성자 오차: {:.4}'.format(loss_val_G))\n",
        "            \n",
        "        #10번 돌때 마다 결과를 그림으로 확인한다.\n",
        "            if epoch == 0 or (epoch + 1) % 25 == 0:\n",
        "                #샘플 이미지의 크기는 10이다.\n",
        "                size = 10\n",
        "                noise = get_noise(size, 128)\n",
        "                #생성자가 임의의 샘플 이미지를  생성하도록 한다.\n",
        "                samples = sess.run(G, feed_dict={Z: noise})\n",
        "        #만든 그림을 폴더에서 출력할 수 있다.\n",
        "                fig, ax = plt.subplots(1, size, figsize=(size, 1))\n",
        "    \n",
        "                for i in range(size):\n",
        "                    ax[i].set_axis_off()\n",
        "                    #28*28 크기의 이미지 생성한다.\n",
        "                    ax[i].imshow(np.reshape(samples[i], (28, 28)))\n",
        "    \n",
        "                plt.savefig('samples{}.png'.format(str(epoch).zfill(4)),\n",
        "                    bbox_inches='tight')\n",
        "                plt.close(fig)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
            "학습: 0000 구분자 오차: -0.518 생성자 오차: -1.71\n",
            "학습: 0001 구분자 오차: -0.248 생성자 오차: -2.369\n",
            "학습: 0002 구분자 오차: -0.2267 생성자 오차: -2.354\n",
            "학습: 0003 구분자 오차: -0.537 생성자 오차: -1.701\n",
            "학습: 0004 구분자 오차: -0.232 생성자 오차: -2.574\n",
            "학습: 0005 구분자 오차: -0.2699 생성자 오차: -2.646\n",
            "학습: 0006 구분자 오차: -0.1945 생성자 오차: -2.567\n",
            "학습: 0007 구분자 오차: -0.2276 생성자 오차: -2.863\n",
            "학습: 0008 구분자 오차: -0.2689 생성자 오차: -2.692\n",
            "학습: 0009 구분자 오차: -0.2409 생성자 오차: -3.081\n",
            "학습: 0010 구분자 오차: -0.4911 생성자 오차: -2.23\n",
            "학습: 0011 구분자 오차: -0.3411 생성자 오차: -2.673\n",
            "학습: 0012 구분자 오차: -0.2398 생성자 오차: -2.939\n",
            "학습: 0013 구분자 오차: -0.3756 생성자 오차: -2.556\n",
            "학습: 0014 구분자 오차: -0.3919 생성자 오차: -2.537\n",
            "학습: 0015 구분자 오차: -0.3606 생성자 오차: -2.518\n",
            "학습: 0016 구분자 오차: -0.3885 생성자 오차: -2.377\n",
            "학습: 0017 구분자 오차: -0.4278 생성자 오차: -2.556\n",
            "학습: 0018 구분자 오차: -0.4757 생성자 오차: -2.524\n",
            "학습: 0019 구분자 오차: -0.3499 생성자 오차: -2.56\n",
            "학습: 0020 구분자 오차: -0.343 생성자 오차: -2.639\n",
            "학습: 0021 구분자 오차: -0.2935 생성자 오차: -2.843\n",
            "학습: 0022 구분자 오차: -0.2708 생성자 오차: -2.573\n",
            "학습: 0023 구분자 오차: -0.2863 생성자 오차: -2.892\n",
            "학습: 0024 구분자 오차: -0.6852 생성자 오차: -2.277\n",
            "학습: 0025 구분자 오차: -0.6135 생성자 오차: -2.109\n",
            "학습: 0026 구분자 오차: -0.4564 생성자 오차: -2.78\n",
            "학습: 0027 구분자 오차: -0.6072 생성자 오차: -2.557\n",
            "학습: 0028 구분자 오차: -0.5019 생성자 오차: -2.541\n",
            "학습: 0029 구분자 오차: -0.506 생성자 오차: -2.658\n",
            "학습: 0030 구분자 오차: -0.3943 생성자 오차: -2.437\n",
            "학습: 0031 구분자 오차: -0.465 생성자 오차: -2.519\n",
            "학습: 0032 구분자 오차: -0.5165 생성자 오차: -2.078\n",
            "학습: 0033 구분자 오차: -0.585 생성자 오차: -2.146\n",
            "학습: 0034 구분자 오차: -0.6422 생성자 오차: -2.128\n",
            "학습: 0035 구분자 오차: -0.4304 생성자 오차: -2.616\n",
            "학습: 0036 구분자 오차: -0.7147 생성자 오차: -2.316\n",
            "학습: 0037 구분자 오차: -0.7161 생성자 오차: -2.228\n",
            "학습: 0038 구분자 오차: -0.7323 생성자 오차: -2.112\n",
            "학습: 0039 구분자 오차: -0.5952 생성자 오차: -2.29\n",
            "학습: 0040 구분자 오차: -0.597 생성자 오차: -2.143\n",
            "학습: 0041 구분자 오차: -0.5875 생성자 오차: -1.908\n",
            "학습: 0042 구분자 오차: -0.7071 생성자 오차: -2.371\n",
            "학습: 0043 구분자 오차: -0.8054 생성자 오차: -1.929\n",
            "학습: 0044 구분자 오차: -0.625 생성자 오차: -2.262\n",
            "학습: 0045 구분자 오차: -0.9422 생성자 오차: -1.938\n",
            "학습: 0046 구분자 오차: -0.71 생성자 오차: -1.816\n",
            "학습: 0047 구분자 오차: -0.8391 생성자 오차: -1.803\n",
            "학습: 0048 구분자 오차: -0.7093 생성자 오차: -1.932\n",
            "학습: 0049 구분자 오차: -0.8438 생성자 오차: -1.543\n",
            "학습: 0050 구분자 오차: -0.6922 생성자 오차: -1.98\n",
            "학습: 0051 구분자 오차: -0.8729 생성자 오차: -1.869\n",
            "학습: 0052 구분자 오차: -0.7909 생성자 오차: -1.818\n",
            "학습: 0053 구분자 오차: -0.967 생성자 오차: -1.592\n",
            "학습: 0054 구분자 오차: -0.919 생성자 오차: -1.874\n",
            "학습: 0055 구분자 오차: -0.8359 생성자 오차: -1.55\n",
            "학습: 0056 구분자 오차: -0.9235 생성자 오차: -1.912\n",
            "학습: 0057 구분자 오차: -0.9477 생성자 오차: -1.617\n",
            "학습: 0058 구분자 오차: -0.8096 생성자 오차: -1.766\n",
            "학습: 0059 구분자 오차: -1.027 생성자 오차: -1.746\n",
            "학습: 0060 구분자 오차: -0.6877 생성자 오차: -1.785\n",
            "학습: 0061 구분자 오차: -0.8928 생성자 오차: -1.672\n",
            "학습: 0062 구분자 오차: -1.044 생성자 오차: -1.742\n",
            "학습: 0063 구분자 오차: -0.8933 생성자 오차: -1.727\n",
            "학습: 0064 구분자 오차: -0.8976 생성자 오차: -1.806\n",
            "학습: 0065 구분자 오차: -0.7946 생성자 오차: -1.626\n",
            "학습: 0066 구분자 오차: -0.9086 생성자 오차: -1.693\n",
            "학습: 0067 구분자 오차: -0.7872 생성자 오차: -1.838\n",
            "학습: 0068 구분자 오차: -0.8418 생성자 오차: -1.621\n",
            "학습: 0069 구분자 오차: -0.8175 생성자 오차: -1.646\n",
            "학습: 0070 구분자 오차: -0.8384 생성자 오차: -1.728\n",
            "학습: 0071 구분자 오차: -0.8091 생성자 오차: -1.761\n",
            "학습: 0072 구분자 오차: -0.7373 생성자 오차: -1.836\n",
            "학습: 0073 구분자 오차: -0.6997 생성자 오차: -1.762\n",
            "학습: 0074 구분자 오차: -0.7556 생성자 오차: -1.669\n",
            "학습: 0075 구분자 오차: -0.9492 생성자 오차: -1.591\n",
            "학습: 0076 구분자 오차: -0.9609 생성자 오차: -1.668\n",
            "학습: 0077 구분자 오차: -0.8623 생성자 오차: -1.567\n",
            "학습: 0078 구분자 오차: -0.9927 생성자 오차: -1.935\n",
            "학습: 0079 구분자 오차: -0.8888 생성자 오차: -1.495\n",
            "학습: 0080 구분자 오차: -0.6998 생성자 오차: -1.914\n",
            "학습: 0081 구분자 오차: -0.7652 생성자 오차: -1.645\n",
            "학습: 0082 구분자 오차: -0.8399 생성자 오차: -1.75\n",
            "학습: 0083 구분자 오차: -0.975 생성자 오차: -1.661\n",
            "학습: 0084 구분자 오차: -0.7833 생성자 오차: -1.569\n",
            "학습: 0085 구분자 오차: -0.9018 생성자 오차: -1.728\n",
            "학습: 0086 구분자 오차: -0.9017 생성자 오차: -1.614\n",
            "학습: 0087 구분자 오차: -0.8019 생성자 오차: -1.679\n",
            "학습: 0088 구분자 오차: -0.7846 생성자 오차: -1.874\n",
            "학습: 0089 구분자 오차: -0.7597 생성자 오차: -1.7\n",
            "학습: 0090 구분자 오차: -0.6987 생성자 오차: -1.772\n",
            "학습: 0091 구분자 오차: -0.7443 생성자 오차: -1.785\n",
            "학습: 0092 구분자 오차: -0.8616 생성자 오차: -1.651\n",
            "학습: 0093 구분자 오차: -0.8403 생성자 오차: -1.755\n",
            "학습: 0094 구분자 오차: -0.8262 생성자 오차: -1.818\n",
            "학습: 0095 구분자 오차: -0.9353 생성자 오차: -2.054\n",
            "학습: 0096 구분자 오차: -0.9189 생성자 오차: -1.792\n",
            "학습: 0097 구분자 오차: -0.7988 생성자 오차: -1.78\n",
            "학습: 0098 구분자 오차: -0.7169 생성자 오차: -1.762\n",
            "학습: 0099 구분자 오차: -0.7591 생성자 오차: -1.793\n",
            "학습: 0100 구분자 오차: -0.6514 생성자 오차: -1.85\n",
            "학습: 0101 구분자 오차: -0.7414 생성자 오차: -1.748\n",
            "학습: 0102 구분자 오차: -0.7303 생성자 오차: -1.828\n",
            "학습: 0103 구분자 오차: -0.8175 생성자 오차: -1.597\n",
            "학습: 0104 구분자 오차: -0.7788 생성자 오차: -1.673\n",
            "학습: 0105 구분자 오차: -0.7522 생성자 오차: -1.765\n",
            "학습: 0106 구분자 오차: -0.796 생성자 오차: -1.953\n",
            "학습: 0107 구분자 오차: -0.7893 생성자 오차: -1.737\n",
            "학습: 0108 구분자 오차: -0.7792 생성자 오차: -1.797\n",
            "학습: 0109 구분자 오차: -0.6737 생성자 오차: -2.106\n",
            "학습: 0110 구분자 오차: -0.7181 생성자 오차: -1.887\n",
            "학습: 0111 구분자 오차: -0.7128 생성자 오차: -2.148\n",
            "학습: 0112 구분자 오차: -0.7099 생성자 오차: -1.927\n",
            "학습: 0113 구분자 오차: -0.8262 생성자 오차: -1.849\n",
            "학습: 0114 구분자 오차: -0.7565 생성자 오차: -1.7\n",
            "학습: 0115 구분자 오차: -0.6582 생성자 오차: -1.918\n",
            "학습: 0116 구분자 오차: -0.7552 생성자 오차: -2.036\n",
            "학습: 0117 구분자 오차: -0.7103 생성자 오차: -1.904\n",
            "학습: 0118 구분자 오차: -0.8997 생성자 오차: -1.893\n",
            "학습: 0119 구분자 오차: -0.9502 생성자 오차: -1.951\n",
            "학습: 0120 구분자 오차: -0.7903 생성자 오차: -1.838\n",
            "학습: 0121 구분자 오차: -0.6583 생성자 오차: -1.878\n",
            "학습: 0122 구분자 오차: -0.7476 생성자 오차: -1.726\n",
            "학습: 0123 구분자 오차: -0.8138 생성자 오차: -2.03\n",
            "학습: 0124 구분자 오차: -0.7145 생성자 오차: -2.024\n",
            "학습: 0125 구분자 오차: -0.6903 생성자 오차: -1.909\n",
            "학습: 0126 구분자 오차: -0.7329 생성자 오차: -2.045\n",
            "학습: 0127 구분자 오차: -0.7696 생성자 오차: -1.851\n",
            "학습: 0128 구분자 오차: -0.9158 생성자 오차: -1.718\n",
            "학습: 0129 구분자 오차: -0.7851 생성자 오차: -1.906\n",
            "학습: 0130 구분자 오차: -0.5952 생성자 오차: -2.178\n",
            "학습: 0131 구분자 오차: -0.7183 생성자 오차: -1.941\n",
            "학습: 0132 구분자 오차: -0.6859 생성자 오차: -1.975\n",
            "학습: 0133 구분자 오차: -0.551 생성자 오차: -2.279\n",
            "학습: 0134 구분자 오차: -0.7267 생성자 오차: -2.253\n",
            "학습: 0135 구분자 오차: -0.59 생성자 오차: -2.113\n",
            "학습: 0136 구분자 오차: -0.6684 생성자 오차: -2.03\n",
            "학습: 0137 구분자 오차: -0.7077 생성자 오차: -1.695\n",
            "학습: 0138 구분자 오차: -0.5896 생성자 오차: -2.145\n",
            "학습: 0139 구분자 오차: -0.765 생성자 오차: -1.911\n",
            "학습: 0140 구분자 오차: -0.6247 생성자 오차: -2.03\n",
            "학습: 0141 구분자 오차: -0.6284 생성자 오차: -2.166\n",
            "학습: 0142 구분자 오차: -0.7001 생성자 오차: -2.255\n",
            "학습: 0143 구분자 오차: -0.6031 생성자 오차: -1.916\n",
            "학습: 0144 구분자 오차: -0.7105 생성자 오차: -1.862\n",
            "학습: 0145 구분자 오차: -0.626 생성자 오차: -2.265\n",
            "학습: 0146 구분자 오차: -0.7483 생성자 오차: -2.205\n",
            "학습: 0147 구분자 오차: -0.6494 생성자 오차: -2.304\n",
            "학습: 0148 구분자 오차: -0.663 생성자 오차: -2.247\n",
            "학습: 0149 구분자 오차: -0.5707 생성자 오차: -2.244\n",
            "학습: 0150 구분자 오차: -0.5721 생성자 오차: -1.965\n",
            "학습: 0151 구분자 오차: -0.6457 생성자 오차: -1.897\n",
            "학습: 0152 구분자 오차: -0.6596 생성자 오차: -1.905\n",
            "학습: 0153 구분자 오차: -0.7096 생성자 오차: -2.109\n",
            "학습: 0154 구분자 오차: -0.602 생성자 오차: -1.831\n",
            "학습: 0155 구분자 오차: -0.6098 생성자 오차: -2.35\n",
            "학습: 0156 구분자 오차: -0.7688 생성자 오차: -2.136\n",
            "학습: 0157 구분자 오차: -0.5807 생성자 오차: -2.411\n",
            "학습: 0158 구분자 오차: -0.6113 생성자 오차: -2.079\n",
            "학습: 0159 구분자 오차: -0.6707 생성자 오차: -2.22\n",
            "학습: 0160 구분자 오차: -0.5921 생성자 오차: -2.334\n",
            "학습: 0161 구분자 오차: -0.6077 생성자 오차: -2.556\n",
            "학습: 0162 구분자 오차: -0.6154 생성자 오차: -2.144\n",
            "학습: 0163 구분자 오차: -0.5651 생성자 오차: -2.334\n",
            "학습: 0164 구분자 오차: -0.6405 생성자 오차: -2.276\n",
            "학습: 0165 구분자 오차: -0.648 생성자 오차: -1.983\n",
            "학습: 0166 구분자 오차: -0.5368 생성자 오차: -2.227\n",
            "학습: 0167 구분자 오차: -0.5796 생성자 오차: -2.414\n",
            "학습: 0168 구분자 오차: -0.7035 생성자 오차: -2.225\n",
            "학습: 0169 구분자 오차: -0.5962 생성자 오차: -2.114\n",
            "학습: 0170 구분자 오차: -0.5994 생성자 오차: -2.338\n",
            "학습: 0171 구분자 오차: -0.6171 생성자 오차: -2.103\n",
            "학습: 0172 구분자 오차: -0.5595 생성자 오차: -2.148\n",
            "학습: 0173 구분자 오차: -0.6653 생성자 오차: -2.248\n",
            "학습: 0174 구분자 오차: -0.564 생성자 오차: -2.765\n",
            "학습: 0175 구분자 오차: -0.4114 생성자 오차: -2.599\n",
            "학습: 0176 구분자 오차: -0.5996 생성자 오차: -2.736\n",
            "학습: 0177 구분자 오차: -0.5378 생성자 오차: -2.288\n",
            "학습: 0178 구분자 오차: -0.5974 생성자 오차: -2.23\n",
            "학습: 0179 구분자 오차: -0.5621 생성자 오차: -2.463\n",
            "학습: 0180 구분자 오차: -0.6688 생성자 오차: -2.401\n",
            "학습: 0181 구분자 오차: -0.6209 생성자 오차: -2.249\n",
            "학습: 0182 구분자 오차: -0.5758 생성자 오차: -2.457\n",
            "학습: 0183 구분자 오차: -0.5639 생성자 오차: -2.426\n",
            "학습: 0184 구분자 오차: -0.5125 생성자 오차: -2.524\n",
            "학습: 0185 구분자 오차: -0.4754 생성자 오차: -2.302\n",
            "학습: 0186 구분자 오차: -0.4989 생성자 오차: -2.603\n",
            "학습: 0187 구분자 오차: -0.6761 생성자 오차: -2.101\n",
            "학습: 0188 구분자 오차: -0.5828 생성자 오차: -2.335\n",
            "학습: 0189 구분자 오차: -0.5837 생성자 오차: -2.09\n",
            "학습: 0190 구분자 오차: -0.651 생성자 오차: -2.284\n",
            "학습: 0191 구분자 오차: -0.4249 생성자 오차: -2.594\n",
            "학습: 0192 구분자 오차: -0.4614 생성자 오차: -3.047\n",
            "학습: 0193 구분자 오차: -0.6217 생성자 오차: -2.3\n",
            "학습: 0194 구분자 오차: -0.6569 생성자 오차: -2.619\n",
            "학습: 0195 구분자 오차: -0.5658 생성자 오차: -2.639\n",
            "학습: 0196 구분자 오차: -0.5548 생성자 오차: -2.493\n",
            "학습: 0197 구분자 오차: -0.4791 생성자 오차: -2.442\n",
            "학습: 0198 구분자 오차: -0.4944 생성자 오차: -2.595\n",
            "학습: 0199 구분자 오차: -0.6052 생성자 오차: -2.284\n",
            "학습: 0200 구분자 오차: -0.4591 생성자 오차: -2.444\n",
            "학습: 0201 구분자 오차: -0.5808 생성자 오차: -2.268\n",
            "학습: 0202 구분자 오차: -0.606 생성자 오차: -2.517\n",
            "학습: 0203 구분자 오차: -0.5487 생성자 오차: -2.486\n",
            "학습: 0204 구분자 오차: -0.6114 생성자 오차: -2.65\n",
            "학습: 0205 구분자 오차: -0.63 생성자 오차: -2.546\n",
            "학습: 0206 구분자 오차: -0.5613 생성자 오차: -2.366\n",
            "학습: 0207 구분자 오차: -0.4933 생성자 오차: -2.584\n",
            "학습: 0208 구분자 오차: -0.4655 생성자 오차: -2.559\n",
            "학습: 0209 구분자 오차: -0.441 생성자 오차: -2.437\n",
            "학습: 0210 구분자 오차: -0.6187 생성자 오차: -2.329\n",
            "학습: 0211 구분자 오차: -0.4579 생성자 오차: -2.702\n",
            "학습: 0212 구분자 오차: -0.4184 생성자 오차: -2.538\n",
            "학습: 0213 구분자 오차: -0.7087 생성자 오차: -2.755\n",
            "학습: 0214 구분자 오차: -0.5482 생성자 오차: -2.444\n",
            "학습: 0215 구분자 오차: -0.552 생성자 오차: -2.551\n",
            "학습: 0216 구분자 오차: -0.4352 생성자 오차: -2.571\n",
            "학습: 0217 구분자 오차: -0.5789 생성자 오차: -2.742\n",
            "학습: 0218 구분자 오차: -0.522 생성자 오차: -2.518\n",
            "학습: 0219 구분자 오차: -0.4836 생성자 오차: -2.725\n",
            "학습: 0220 구분자 오차: -0.5167 생성자 오차: -2.493\n",
            "학습: 0221 구분자 오차: -0.4829 생성자 오차: -2.27\n",
            "학습: 0222 구분자 오차: -0.4882 생성자 오차: -2.549\n",
            "학습: 0223 구분자 오차: -0.641 생성자 오차: -2.575\n",
            "학습: 0224 구분자 오차: -0.5543 생성자 오차: -2.399\n",
            "학습: 0225 구분자 오차: -0.4264 생성자 오차: -2.602\n",
            "학습: 0226 구분자 오차: -0.5572 생성자 오차: -2.846\n",
            "학습: 0227 구분자 오차: -0.5054 생성자 오차: -2.358\n",
            "학습: 0228 구분자 오차: -0.6349 생성자 오차: -2.464\n",
            "학습: 0229 구분자 오차: -0.5704 생성자 오차: -2.438\n",
            "학습: 0230 구분자 오차: -0.3943 생성자 오차: -3.007\n",
            "학습: 0231 구분자 오차: -0.4756 생성자 오차: -2.8\n",
            "학습: 0232 구분자 오차: -0.4811 생성자 오차: -2.781\n",
            "학습: 0233 구분자 오차: -0.4683 생성자 오차: -2.916\n",
            "학습: 0234 구분자 오차: -0.6888 생성자 오차: -2.377\n",
            "학습: 0235 구분자 오차: -0.5218 생성자 오차: -2.748\n",
            "학습: 0236 구분자 오차: -0.5252 생성자 오차: -2.432\n",
            "학습: 0237 구분자 오차: -0.5514 생성자 오차: -2.373\n",
            "학습: 0238 구분자 오차: -0.6582 생성자 오차: -2.527\n",
            "학습: 0239 구분자 오차: -0.5883 생성자 오차: -2.604\n",
            "학습: 0240 구분자 오차: -0.6838 생성자 오차: -2.392\n",
            "학습: 0241 구분자 오차: -0.5699 생성자 오차: -2.602\n",
            "학습: 0242 구분자 오차: -0.4853 생성자 오차: -3.037\n",
            "학습: 0243 구분자 오차: -0.4274 생성자 오차: -2.706\n",
            "학습: 0244 구분자 오차: -0.4832 생성자 오차: -2.951\n",
            "학습: 0245 구분자 오차: -0.4511 생성자 오차: -2.957\n",
            "학습: 0246 구분자 오차: -0.4882 생성자 오차: -2.772\n",
            "학습: 0247 구분자 오차: -0.4806 생성자 오차: -2.435\n",
            "학습: 0248 구분자 오차: -0.4126 생성자 오차: -2.699\n",
            "학습: 0249 구분자 오차: -0.3347 생성자 오차: -3.029\n",
            "학습: 0250 구분자 오차: -0.4455 생성자 오차: -2.682\n",
            "학습: 0251 구분자 오차: -0.5063 생성자 오차: -2.676\n",
            "학습: 0252 구분자 오차: -0.5626 생성자 오차: -2.883\n",
            "학습: 0253 구분자 오차: -0.521 생성자 오차: -2.497\n",
            "학습: 0254 구분자 오차: -0.467 생성자 오차: -2.828\n",
            "학습: 0255 구분자 오차: -0.4233 생성자 오차: -2.685\n",
            "학습: 0256 구분자 오차: -0.4222 생성자 오차: -2.572\n",
            "학습: 0257 구분자 오차: -0.5432 생성자 오차: -2.84\n",
            "학습: 0258 구분자 오차: -0.4426 생성자 오차: -2.958\n",
            "학습: 0259 구분자 오차: -0.4937 생성자 오차: -3.024\n",
            "학습: 0260 구분자 오차: -0.5731 생성자 오차: -2.933\n",
            "학습: 0261 구분자 오차: -0.4799 생성자 오차: -3.067\n",
            "학습: 0262 구분자 오차: -0.4656 생성자 오차: -2.613\n",
            "학습: 0263 구분자 오차: -0.5941 생성자 오차: -2.524\n",
            "학습: 0264 구분자 오차: -0.4163 생성자 오차: -2.586\n",
            "학습: 0265 구분자 오차: -0.0003885 생성자 오차: -inf\n",
            "학습: 0266 구분자 오차: -0.0001147 생성자 오차: -inf\n",
            "학습: 0267 구분자 오차: -6.17e-05 생성자 오차: -inf\n",
            "학습: 0268 구분자 오차: -0.0001064 생성자 오차: -inf\n",
            "학습: 0269 구분자 오차: -2.182e-05 생성자 오차: -inf\n",
            "학습: 0270 구분자 오차: -2.487e-05 생성자 오차: -inf\n",
            "학습: 0271 구분자 오차: -8.198e-06 생성자 오차: -inf\n",
            "학습: 0272 구분자 오차: -3.842e-06 생성자 오차: -inf\n",
            "학습: 0273 구분자 오차: -2.368e-05 생성자 오차: -inf\n",
            "학습: 0274 구분자 오차: -4.425e-06 생성자 오차: -inf\n",
            "학습: 0275 구분자 오차: -6.369e-05 생성자 오차: -inf\n",
            "학습: 0276 구분자 오차: -2.925e-06 생성자 오차: -inf\n",
            "학습: 0277 구분자 오차: -5.448e-07 생성자 오차: -inf\n",
            "학습: 0278 구분자 오차: -9.155e-07 생성자 오차: -inf\n",
            "학습: 0279 구분자 오차: -2.76e-07 생성자 오차: -inf\n",
            "학습: 0280 구분자 오차: -1.771e-05 생성자 오차: -inf\n",
            "학습: 0281 구분자 오차: -4.506e-07 생성자 오차: -inf\n",
            "학습: 0282 구분자 오차: -9.275e-07 생성자 오차: -inf\n",
            "학습: 0283 구분자 오차: -7.808e-08 생성자 오차: -inf\n",
            "학습: 0284 구분자 오차: -1.132e-07 생성자 오차: -inf\n",
            "학습: 0285 구분자 오차: -1.103e-07 생성자 오차: -inf\n",
            "학습: 0286 구분자 오차: -2.313e-07 생성자 오차: -inf\n",
            "학습: 0287 구분자 오차: -6.676e-08 생성자 오차: -inf\n",
            "학습: 0288 구분자 오차: -3.576e-09 생성자 오차: -inf\n",
            "학습: 0289 구분자 오차: -8.583e-08 생성자 오차: -inf\n",
            "학습: 0290 구분자 오차: -6.557e-08 생성자 오차: -inf\n",
            "학습: 0291 구분자 오차: -1.609e-08 생성자 오차: -inf\n",
            "학습: 0292 구분자 오차: -7.808e-08 생성자 오차: -inf\n",
            "학습: 0293 구분자 오차: -1.329e-07 생성자 오차: -inf\n",
            "학습: 0294 구분자 오차: -2.98e-08 생성자 오차: -inf\n",
            "학습: 0295 구분자 오차: -2.98e-09 생성자 오차: -inf\n",
            "학습: 0296 구분자 오차: -5.364e-09 생성자 오차: -inf\n",
            "학습: 0297 구분자 오차: -8.345e-09 생성자 오차: -inf\n",
            "학습: 0298 구분자 오차: -5.364e-09 생성자 오차: -inf\n",
            "학습: 0299 구분자 오차: -1.788e-09 생성자 오차: -inf\n",
            "학습: 0300 구분자 오차: -6.557e-09 생성자 오차: -inf\n",
            "학습: 0301 구분자 오차: 0.0 생성자 오차: -inf\n",
            "학습: 0302 구분자 오차: -1.132e-08 생성자 오차: -inf\n",
            "학습: 0303 구분자 오차: -2.384e-09 생성자 오차: -inf\n",
            "학습: 0304 구분자 오차: -2.384e-09 생성자 오차: -inf\n",
            "학습: 0305 구분자 오차: 0.0 생성자 오차: -inf\n",
            "학습: 0306 구분자 오차: 0.0 생성자 오차: -inf\n",
            "학습: 0307 구분자 오차: 0.0 생성자 오차: -inf\n",
            "학습: 0308 구분자 오차: 0.0 생성자 오차: -inf\n",
            "학습: 0309 구분자 오차: -1.192e-09 생성자 오차: -inf\n",
            "학습: 0310 구분자 오차: -1.192e-09 생성자 오차: -inf\n",
            "학습: 0311 구분자 오차: 0.0 생성자 오차: -inf\n",
            "학습: 0312 구분자 오차: 0.0 생성자 오차: -inf\n",
            "학습: 0313 구분자 오차: 0.0 생성자 오차: -inf\n",
            "학습: 0314 구분자 오차: 0.0 생성자 오차: -inf\n",
            "학습: 0315 구분자 오차: 0.0 생성자 오차: -inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-8ef78ce12d36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m#구분자는 실제 이미지 및 노이즈를 이용해 학습을 진행시킨다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 _, loss_val_D = sess.run([train_D, loss_D],\n\u001b[0;32m---> 85\u001b[0;31m                     feed_dict={X: batch_x, Z: noise})\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;31m#생성자는 노이즈만을 이용해 학습 진행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 _, loss_val_G = sess.run([train_G, loss_G],\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnAZ-SleCdUx",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}